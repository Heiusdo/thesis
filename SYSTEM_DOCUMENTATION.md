# ğŸ“š TÃ i Liá»‡u Há»‡ Thá»‘ng - Sentiment Analysis vá»›i RoBERTa

## ğŸ“‹ Tá»•ng Quan Dá»± Ãn

ÄÃ¢y lÃ  há»‡ thá»‘ng **phÃ¢n tÃ­ch cáº£m xÃºc Ä‘a lá»›p (Multi-class Sentiment Analysis)** sá»­ dá»¥ng mÃ´ hÃ¬nh **RoBERTa** Ä‘Æ°á»£c fine-tune. Há»‡ thá»‘ng Ä‘Æ°á»£c xÃ¢y dá»±ng cho má»¥c Ä‘Ã­ch luáº­n vÄƒn vá»›i tÃªn: *"Domain-focused Sentiment Analysis for Brand Monitoring using Pre-trained RoBERTa"*.

### ğŸ¯ Má»¥c TiÃªu
- PhÃ¢n loáº¡i vÄƒn báº£n thÃ nh **3 lá»›p cáº£m xÃºc**: Negative (0), Neutral (1), Positive (2)
- Äáº¡t hiá»‡u suáº¥t cao hÆ¡n cÃ¡c baseline truyá»n thá»‘ng (Logistic Regression, SVM)
- Cung cáº¥p giao diá»‡n web Ä‘á»ƒ demo vÃ  sá»­ dá»¥ng

---

## ğŸ“ Cáº¥u TrÃºc ThÆ° Má»¥c

```
src/
â”œâ”€â”€ train_sentiment_roberta.py    # Script huáº¥n luyá»‡n model RoBERTa
â”œâ”€â”€ UI.py                         # Giao diá»‡n Streamlit Dashboard
â”œâ”€â”€ download_data.py              # Script táº£i dataset tá»« HuggingFace
â”œâ”€â”€ Baseline.ipynb                # Notebook so sÃ¡nh vá»›i Logistic Regression & SVM
â”œâ”€â”€ processData.ipynb             # Notebook tiá»n xá»­ lÃ½ dá»¯ liá»‡u
â”œâ”€â”€ visualize.ipynb               # Notebook trá»±c quan hÃ³a káº¿t quáº£
â”œâ”€â”€ metrics.csv                   # Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ model (Ä‘Ã£ train)
â”œâ”€â”€ train.csv / valid.csv / test.csv  # Dá»¯ liá»‡u Ä‘Ã£ tiá»n xá»­ lÃ½
â”œâ”€â”€ data/                         # ThÆ° má»¥c chá»©a raw data
â”‚   â”œâ”€â”€ multiclass_sentiment_analysis_dataset_train.csv
â”‚   â”œâ”€â”€ multiclass_sentiment_analysis_dataset_validation.csv
â”‚   â””â”€â”€ multiclass_sentiment_analysis_dataset_test.csv
â””â”€â”€ roberta_sentiment_ckpt/       # Checkpoint model Ä‘Ã£ train
    â”œâ”€â”€ model_state_dict.pt       # Weights cá»§a model
    â”œâ”€â”€ train_config.json         # Config huáº¥n luyá»‡n
    â””â”€â”€ tokenizer/                # Tokenizer Ä‘Ã£ lÆ°u
```

---

## ğŸ”§ Chi Tiáº¿t Tá»«ng File

### 1. `train_sentiment_roberta.py` - Script Huáº¥n Luyá»‡n

**Má»¥c Ä‘Ã­ch**: Fine-tune mÃ´ hÃ¬nh RoBERTa cho phÃ¢n loáº¡i cáº£m xÃºc.

#### CÃ¡c Class ChÃ­nh:

| Class | MÃ´ Táº£ |
|-------|-------|
| `TrainConfig` | Dataclass chá»©a cáº¥u hÃ¬nh huáº¥n luyá»‡n (model_name, epochs, learning rate, batch size, ...) |
| `SentimentDataset` | PyTorch Dataset Ä‘á»ƒ load vÃ  tokenize dá»¯ liá»‡u |
| `RobertaClassifier` | Model chÃ­nh vá»›i kiáº¿n trÃºc: RoBERTa Encoder â†’ Linear(768â†’768) â†’ ReLU â†’ Dropout â†’ Linear(768â†’num_labels) |

#### CÃ¡c Function ChÃ­nh:

| Function | MÃ´ Táº£ |
|----------|-------|
| `train_one_epoch()` | Huáº¥n luyá»‡n 1 epoch, tráº£ vá» loss vÃ  accuracy |
| `eval_model()` | ÄÃ¡nh giÃ¡ model, tÃ­nh toÃ¡n cÃ¡c metrics (Accuracy, Precision, Recall, F1, ROC-AUC) |
| `save_artifacts()` | LÆ°u model weights, tokenizer, config |
| `write_metrics()` | Ghi káº¿t quáº£ Ä‘Ã¡nh giÃ¡ ra file |

#### CÃ¡ch Sá»­ Dá»¥ng:
```bash
python train_sentiment_roberta.py \
  --train_csv train.csv \
  --test_csv test.csv \
  --output_dir roberta_sentiment_ckpt \
  --metrics_txt metrics.txt \
  --epochs 3 \
  --lr 1e-5
```

#### Cáº¥u HÃ¬nh Máº·c Äá»‹nh:
- **Model**: `cardiffnlp/twitter-roberta-base-sentiment`
- **Max Length**: 256 tokens
- **Batch Size**: Train=64, Eval=32
- **Epochs**: 3
- **Learning Rate**: 1e-5
- **Optimizer**: Adam

---

### 2. `UI.py` - Giao Diá»‡n Web Streamlit

**Má»¥c Ä‘Ã­ch**: Cung cáº¥p dashboard trá»±c quan Ä‘á»ƒ demo model.

#### CÃ¡c TÃ­nh NÄƒng:

1. **Nháº­p liá»‡u**:
   - Nháº­p text thá»§ cÃ´ng (má»—i dÃ²ng 1 cÃ¢u)
   - Upload file CSV/Excel

2. **Dá»± Ä‘oÃ¡n**:
   - Xá»­ lÃ½ theo batch Ä‘á»ƒ trÃ¡nh OOM
   - Hiá»ƒn thá»‹ progress bar vÃ  ETA
   - Táº£i xuá»‘ng káº¿t quáº£ CSV

3. **Trá»±c quan hÃ³a**:
   - Biá»ƒu Ä‘á»“ trÃ²n phÃ¢n bá»‘ cáº£m xÃºc
   - Highlight cÃ¡c dá»± Ä‘oÃ¡n confidence cao (>90%)

#### CÃ¡ch Cháº¡y:
```bash
streamlit run UI.py
```

#### CÃ¡c Function ChÃ­nh:

| Function | MÃ´ Táº£ |
|----------|-------|
| `preprocess_data()` | Tá»± Ä‘á»™ng nháº­n diá»‡n cá»™t text trong file upload |
| `predict_sentiment()` | Dá»± Ä‘oÃ¡n cho batch nhá» |
| `predict_large_dataset()` | Dá»± Ä‘oÃ¡n cho dataset lá»›n vá»›i progress tracking |

---

### 3. `download_data.py` - Táº£i Dataset

**Má»¥c Ä‘Ã­ch**: Táº£i dataset tá»« HuggingFace Hub.

**Dataset**: `Sp1786/multiclass-sentiment-analysis-dataset`

**Output**:
- `data/multiclass_sentiment_analysis_dataset_train.csv`
- `data/multiclass_sentiment_analysis_dataset_validation.csv`
- `data/multiclass_sentiment_analysis_dataset_test.csv`

---

### 4. `Baseline.ipynb` - So SÃ¡nh Baseline

**Má»¥c Ä‘Ã­ch**: So sÃ¡nh hiá»‡u suáº¥t RoBERTa vá»›i cÃ¡c mÃ´ hÃ¬nh truyá»n thá»‘ng.

#### CÃ¡c MÃ´ HÃ¬nh ÄÆ°á»£c So SÃ¡nh:

| Model | Accuracy | Macro F1 |
|-------|----------|----------|
| Logistic Regression + TF-IDF | 68.61% | 0.69 |
| SVM + TF-IDF | 68.00% | 0.68 |
| **RoBERTa (Fine-tuned)** | **72.17%** | **0.72** |

#### Pipeline TF-IDF:
- Lowercase: True
- N-grams: (1, 2)
- Max features: 10,000
- Sublinear TF: True

---

## ğŸ“Š Káº¿t Quáº£ ÄÃ¡nh GiÃ¡ Model

### Cáº¥u HÃ¬nh Huáº¥n Luyá»‡n:
```json
{
  "model_name": "cardiffnlp/twitter-roberta-base-sentiment",
  "num_labels": 3,
  "max_len": 256,
  "train_batch_size": 64,
  "epochs": 3,
  "lr": 1e-05
}
```

### Lá»‹ch Sá»­ Huáº¥n Luyá»‡n:
| Epoch | Train Loss | Train Accuracy |
|-------|------------|----------------|
| 1 | 0.7100 | 69.32% |
| 2 | 0.6266 | 73.29% |
| 3 | 0.5731 | 76.18% |

### Metrics TrÃªn Test Set:

| Metric | GiÃ¡ Trá»‹ |
|--------|---------|
| **Accuracy** | 72.17% |
| **Precision (macro)** | 72.11% |
| **Recall (macro)** | 72.32% |
| **F1-score (macro)** | 72.16% |
| **ROC-AUC (OvR, macro)** | 87.91% |

### Classification Report:
| Class | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| 0 (Negative) | 0.7473 | 0.7328 | 0.7399 | 1029 |
| 1 (Neutral) | 0.6534 | 0.6154 | 0.6339 | 1204 |
| 2 (Positive) | 0.7627 | 0.8214 | 0.7909 | 1170 |

---

## ğŸ”„ Quy TrÃ¬nh LÃ m Viá»‡c

```mermaid
graph TD
    A[Raw Data tá»« HuggingFace] -->|download_data.py| B[Data Files]
    B -->|processData.ipynb| C[Cleaned Data: train/valid/test.csv]
    C -->|train_sentiment_roberta.py| D[Trained Model]
    D -->|roberta_sentiment_ckpt/| E[Saved Checkpoint]
    E -->|UI.py| F[Streamlit Dashboard]
    C -->|Baseline.ipynb| G[Baseline Comparison]
    D -->|visualize.ipynb| H[Visualization]
```

---

## ğŸ“ Kiáº¿n TrÃºc Model RoBERTa Classifier

```
Input Text
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      RobertaTokenizerFast       â”‚
â”‚   (max_length=256, padding)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        RobertaModel             â”‚
â”‚  (cardiffnlp/twitter-roberta-   â”‚
â”‚   base-sentiment)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼ [CLS] token embedding (768-dim)
    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Pre-Classifier (768 â†’ 768)    â”‚
â”‚          + ReLU                 â”‚
â”‚       + Dropout(0.2)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Classifier (768 â†’ 3)         â”‚
â”‚         (num_labels)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Softmax â†’ Logits          â”‚
â”‚  [Negative, Neutral, Positive]  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ HÆ°á»›ng Dáº«n CÃ i Äáº·t & Sá»­ Dá»¥ng

### YÃªu Cáº§u:
```txt
torch
transformers
pandas
numpy
scikit-learn
streamlit
plotly
tqdm
datasets
```

### CÃ¡c BÆ°á»›c:

1. **Táº£i dá»¯ liá»‡u**:
   ```bash
   python download_data.py
   ```

2. **Tiá»n xá»­ lÃ½ dá»¯ liá»‡u**: Cháº¡y `processData.ipynb`

3. **Huáº¥n luyá»‡n model**:
   ```bash
   python train_sentiment_roberta.py \
     --train_csv train.csv \
     --test_csv test.csv
   ```

4. **Cháº¡y Dashboard**:
   ```bash
   streamlit run UI.py
   ```

---

## ğŸ“Œ Ghi ChÃº Quan Trá»ng

1. **GPU**: Script tá»± Ä‘á»™ng detect CUDA, náº¿u cÃ³ sáº½ dÃ¹ng GPU
2. **Memory**: UI sá»­ dá»¥ng batch processing Ä‘á»ƒ trÃ¡nh OOM
3. **Columns**: Data cáº§n cÃ³ `text_clean` vÃ  `label`
4. **Labels**: 0=Negative, 1=Neutral, 2=Positive

---

*TÃ i liá»‡u Ä‘Æ°á»£c táº¡o tá»± Ä‘á»™ng bá»Ÿi AI Assistant - Cáº­p nháº­t: 2025-12-30*
